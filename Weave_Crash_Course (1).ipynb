{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nx6X6aK00RP_",
        "outputId": "566fecf7-70e8-44ea-d7f4-fc305326dee2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: weave in /usr/local/lib/python3.10/dist-packages (0.51.8)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.47.1)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from weave) (4.12.2)\n",
            "Requirement already satisfied: pyarrow<17.0.0,>=14.0.1 in /usr/local/lib/python3.10/dist-packages (from weave) (14.0.2)\n",
            "Requirement already satisfied: tiktoken>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from weave) (0.7.0)\n",
            "Requirement already satisfied: pydantic>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from weave) (2.9.2)\n",
            "Requirement already satisfied: rich>=13.7.0 in /usr/local/lib/python3.10/dist-packages (from weave) (13.8.1)\n",
            "Requirement already satisfied: aiohttp>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from weave) (3.10.5)\n",
            "Requirement already satisfied: aiofiles>=22.1.0 in /usr/local/lib/python3.10/dist-packages (from weave) (24.1.0)\n",
            "Requirement already satisfied: aioprocessing>=2.0.1 in /usr/local/lib/python3.10/dist-packages (from weave) (2.0.1)\n",
            "Requirement already satisfied: Werkzeug>=3.0.3 in /usr/local/lib/python3.10/dist-packages (from weave) (3.0.4)\n",
            "Requirement already satisfied: janus>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from weave) (1.0.0)\n",
            "Requirement already satisfied: python-json-logger>=2.0.4 in /usr/local/lib/python3.10/dist-packages (from weave) (2.0.7)\n",
            "Requirement already satisfied: numpy>=1.21 in /usr/local/lib/python3.10/dist-packages (from weave) (1.26.4)\n",
            "Requirement already satisfied: wandb>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from weave) (0.18.1)\n",
            "Requirement already satisfied: graphql-core>3 in /usr/local/lib/python3.10/dist-packages (from weave) (3.2.4)\n",
            "Requirement already satisfied: gql>=3.4.1 in /usr/local/lib/python3.10/dist-packages (from gql[requests]>=3.4.1->weave) (3.5.0)\n",
            "Requirement already satisfied: analytics-python>=1.2.9 in /usr/local/lib/python3.10/dist-packages (from weave) (1.2.9)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from weave) (2.8.2)\n",
            "Requirement already satisfied: packaging>=21.0 in /usr/local/lib/python3.10/dist-packages (from weave) (24.1)\n",
            "Requirement already satisfied: tenacity!=8.4.0,>=8.3.0 in /usr/local/lib/python3.10/dist-packages (from weave) (9.0.0)\n",
            "Requirement already satisfied: emoji>=2.12.1 in /usr/local/lib/python3.10/dist-packages (from weave) (2.13.2)\n",
            "Requirement already satisfied: uuid-utils>=0.9.0 in /usr/local/lib/python3.10/dist-packages (from weave) (0.9.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.2)\n",
            "Requirement already satisfied: jiter<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.5.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.5)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.3->weave) (2.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.3->weave) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.3->weave) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.3->weave) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.3->weave) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.3->weave) (1.11.1)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp>=3.8.3->weave) (4.0.3)\n",
            "Requirement already satisfied: requests<3.0,>=2.7 in /usr/local/lib/python3.10/dist-packages (from analytics-python>=1.2.9->weave) (2.32.3)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from analytics-python>=1.2.9->weave) (1.16.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.10)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.2)\n",
            "Requirement already satisfied: backoff<3.0,>=1.11.1 in /usr/local/lib/python3.10/dist-packages (from gql>=3.4.1->gql[requests]>=3.4.1->weave) (2.2.1)\n",
            "Requirement already satisfied: requests-toolbelt<2,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from gql[requests]>=3.4.1->weave) (1.0.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.8.30)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->weave) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.23.4 in /usr/local/lib/python3.10/dist-packages (from pydantic>=2.0.0->weave) (2.23.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.7.0->weave) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich>=13.7.0->weave) (2.18.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken>=0.4.0->weave) (2024.9.11)\n",
            "Requirement already satisfied: click!=8.0.0,>=7.1 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.4->weave) (8.1.7)\n",
            "Requirement already satisfied: docker-pycreds>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.4->weave) (0.4.0)\n",
            "Requirement already satisfied: gitpython!=3.1.29,>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.4->weave) (3.1.43)\n",
            "Requirement already satisfied: platformdirs in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.4->weave) (4.3.6)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=5.28.0,<6,>=3.19.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.4->weave) (3.20.3)\n",
            "Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.4->weave) (5.9.5)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.4->weave) (6.0.2)\n",
            "Requirement already satisfied: sentry-sdk>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.4->weave) (2.14.0)\n",
            "Requirement already satisfied: setproctitle in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.4->weave) (1.3.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from wandb>=0.16.4->weave) (71.0.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from Werkzeug>=3.0.3->weave) (2.1.5)\n",
            "Requirement already satisfied: gitdb<5,>=4.0.1 in /usr/local/lib/python3.10/dist-packages (from gitpython!=3.1.29,>=1.0.0->wandb>=0.16.4->weave) (4.0.11)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich>=13.7.0->weave) (0.1.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.7->analytics-python>=1.2.9->weave) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0,>=2.7->analytics-python>=1.2.9->weave) (2.2.3)\n",
            "Requirement already satisfied: smmap<6,>=3.0.1 in /usr/local/lib/python3.10/dist-packages (from gitdb<5,>=4.0.1->gitpython!=3.1.29,>=1.0.0->wandb>=0.16.4->weave) (5.0.1)\n"
          ]
        }
      ],
      "source": [
        "!pip install weave openai"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import weave\n",
        "\n",
        "weave.init(\"rag-baselining\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wNcorLgP0k-B",
        "outputId": "1cdc6f1d-36c9-4fe9-e5c0-711be2c22548"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Logged in as Weights & Biases user: aianytime07.\n",
            "View Weave data at https://wandb.ai/aianytime07/rag-baselining/weave\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<weave.trace.weave_client.WeaveClient at 0x782b5b81e380>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "from google.colab import userdata\n",
        "\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get(\"OPENAI_API_KEY\")"
      ],
      "metadata": {
        "id": "A5Vb6B7J0zg0"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "client = OpenAI()\n",
        "response = client.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": \"Please translate English into Hindi.\"},\n",
        "        {\"role\": \"user\", \"content\": \"AI is a old technology.\"},\n",
        "    ],\n",
        "    temperature=0,\n",
        ")\n",
        "\n",
        "\n",
        "generation = response.choices[0].message.content\n",
        "print(generation)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZE4qCEwO09f9",
        "outputId": "8e29a7d2-1296-4dda-8749-93c2954c8abf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üç© https://wandb.ai/aianytime07/rag-baselining/r/call/019223a3-59c5-7ba1-a23f-31f8f3123e78\n",
            "‡§è‡§Ü‡§à ‡§è‡§ï ‡§™‡•Å‡§∞‡§æ‡§®‡•Ä ‡§§‡§ï‡§®‡•Ä‡§ï ‡§π‡•à‡•§\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recording functions - @weave.op()\n",
        "\n",
        "Append @weave.op() to a function to record the input and output of the function.\n",
        "\n",
        "\n",
        "(1) Add @weave.op\n",
        "to the function. In this example, add @weave.op to the translation() function."
      ],
      "metadata": {
        "id": "W4SkiXUT2nS7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@weave.op()\n",
        "def translation(user_input):\n",
        "    client = OpenAI()\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o-mini\",\n",
        "        messages=[\n",
        "            {\"role\": \"system\", \"content\": \"Please translate English into Hindi.\"},\n",
        "            {\"role\": \"user\", \"content\": user_input},\n",
        "        ],\n",
        "        temperature=0,\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n",
        "result = translation(\"AI is a old technology\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFsFMddj1PNX",
        "outputId": "10a74c4c-cdc6-4fc7-932f-588eb6d517ce"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üç© https://wandb.ai/aianytime07/rag-baselining/r/call/019223a4-e344-7762-85af-dce613c1ec0a\n",
            "‡§è‡§Ü‡§à ‡§è‡§ï ‡§™‡•Å‡§∞‡§æ‡§®‡•Ä ‡§§‡§ï‡§®‡•Ä‡§ï ‡§π‡•à‡•§\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Recording the model - weave.Model\n",
        "\n",
        "(1) Specify weave.Model as the class inheritance base  .\n",
        "\n",
        "In this example, we have the class TranslationModel inherit weave.Model ."
      ],
      "metadata": {
        "id": "HOnw4vbn20Gl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "class TranslationModel(weave.Model):\n",
        "    system_instruction: str\n",
        "\n",
        "    @weave.op()\n",
        "    def translation(self, user_input):\n",
        "        client = OpenAI()\n",
        "        response = client.chat.completions.create(\n",
        "            model=\"gpt-4o-mini\",\n",
        "            messages=[\n",
        "                {\"role\": \"system\", \"content\": self.system_instruction},\n",
        "                {\"role\": \"user\", \"content\": user_input},\n",
        "            ],\n",
        "            temperature=0,\n",
        "        )\n",
        "        return response.choices[0].message.content\n",
        "\n",
        "\n",
        "model = TranslationModel(\n",
        "    system_instruction=\"Please translate English into Hindi.\",\n",
        ")\n",
        "result = model.translation(\"Generative AI has been hyped up a lot.\")\n",
        "print(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iTORBNHb2Z0V",
        "outputId": "382c80eb-3e00-45bd-a780-a054379a90e8"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üç© https://wandb.ai/aianytime07/rag-baselining/r/call/019223a6-2ea1-79d3-9806-f99f120d2287\n",
            "‡§ú‡§®‡§∞‡•á‡§ü‡§ø‡§µ ‡§è‡§Ü‡§à ‡§ï‡•ã ‡§¨‡§π‡•Å‡§§ ‡§Ö‡§ß‡§ø‡§ï ‡§™‡•ç‡§∞‡§ö‡§æ‡§∞‡§ø‡§§ ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Accuracy verification procedure"
      ],
      "metadata": {
        "id": "T8FIPuXv3V3I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "documents = [\n",
        "    \"SpaceX is a private aerospace manufacturer and space transportation company founded by Elon Musk. It has revolutionized the space industry with reusable rockets and aims to enable human life on Mars.\",\n",
        "    \"NASA is the United States government agency responsible for space exploration and research. It has led historic missions like the Apollo moon landings and is currently involved in developing technologies for future space missions.\",\n",
        "    \"Tesla is a leading electric vehicle and clean energy company that focuses on accelerating the transition to sustainable energy. Its innovations include electric cars, solar panels, and energy storage solutions.\",\n",
        "    \"Blue Origin is an aerospace company founded by Jeff Bezos, aiming to make space travel more affordable and accessible. It is known for its suborbital space tourism program and development of reusable rockets.\",\n",
        "    \"Boeing is a major American corporation in the aerospace industry, manufacturing commercial airplanes, defense systems, and satellites. Boeing has a long history of contributions to aviation and space exploration.\",\n",
        "    \"Virgin Galactic is a space tourism company founded by Richard Branson. It focuses on providing commercial suborbital spaceflights for passengers, aiming to make space travel accessible to more people.\"\n",
        "]"
      ],
      "metadata": {
        "id": "hQPex8hQ3GlC"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from openai import OpenAI\n",
        "\n",
        "\n",
        "def docs_to_embeddings(docs: list) -> list:\n",
        "    openai = OpenAI()\n",
        "    document_embeddings = []\n",
        "    for doc in docs:\n",
        "        response = (\n",
        "            openai.embeddings.create(\n",
        "                input=doc,\n",
        "                model=\"text-embedding-3-small\"\n",
        "            )\n",
        "            .data[0]\n",
        "            .embedding\n",
        "        )\n",
        "        document_embeddings.append(response)\n",
        "    return document_embeddings\n",
        "\n",
        "\n",
        "docs_embeddings = docs_to_embeddings(documents)"
      ],
      "metadata": {
        "id": "O7u8PXsE3o6h"
      },
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "\n",
        "@weave.op()\n",
        "def get_most_relevant_document(query):\n",
        "\n",
        "    openai = OpenAI()\n",
        "    query_embedding = (\n",
        "        openai.embeddings.create(\n",
        "            input=query,\n",
        "            model=\"text-embedding-3-small\"\n",
        "        )\n",
        "        .data[0]\n",
        "        .embedding\n",
        "    )\n",
        "\n",
        "\n",
        "    similarities = [\n",
        "        np.dot(query_embedding, doc_emb)\n",
        "        / (np.linalg.norm(query_embedding) * np.linalg.norm(doc_emb))\n",
        "        for doc_emb in docs_embeddings\n",
        "    ]\n",
        "\n",
        "\n",
        "    most_relevant_doc_index = np.argmax(similarities)\n",
        "    return documents[most_relevant_doc_index]"
      ],
      "metadata": {
        "id": "_5ONZjKw3tQ-"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We define a model in ‚ÄúWeave‚Äù to collect the information necessary for evaluating the RAG system.\n",
        "\n",
        "„ÉªAttribute : model_name\n",
        "\n",
        "„ÉªFunction : predict()\n",
        "\n",
        "„ÄÄSpecify \"question\" as input and \"answer\" and \"context\" as output"
      ],
      "metadata": {
        "id": "RxxhTnNH4XfZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class RAGModel(weave.Model):\n",
        "    model_name: str = \"gpt-4o\"\n",
        "\n",
        "\n",
        "    @weave.op()\n",
        "    def predict(self, question: str) -> dict:\n",
        "\n",
        "        context = get_most_relevant_document(question)\n",
        "\n",
        "\n",
        "        client = OpenAI()\n",
        "        query = f\"\"\"Please answer the questions using only the following context.\n",
        "If you don't know the answer, answer 'I don't know.'\n",
        "\n",
        "\n",
        "context:\"\n",
        "```\n",
        "{context}\n",
        "```\n",
        "\n",
        "question:\n",
        "{question}\"\"\"\n",
        "        response = client.chat.completions.create(\n",
        "            model=self.model_name,\n",
        "            messages=[\n",
        "                {\"role\": \"user\", \"content\": query},\n",
        "            ],\n",
        "            temperature=0.0,\n",
        "            response_format={\"type\": \"text\"},\n",
        "        )\n",
        "        answer = response.choices[0].message.content\n",
        "        return {\"answer\": answer, \"context\": context}"
      ],
      "metadata": {
        "id": "8m-8xsFu30ux"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = RAGModel(\n",
        "    model_name=\"gpt-4o\"\n",
        ")\n",
        "model.predict(\"What is NASA?\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mySDJJso4ScP",
        "outputId": "21badf87-c407-4493-8453-f66a111afb91"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üç© https://wandb.ai/aianytime07/rag-baselining/r/call/019223a9-68b6-70c0-a581-85488f287370\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'answer': 'NASA is the United States government agency responsible for space exploration and research.',\n",
              " 'context': 'NASA is the United States government agency responsible for space exploration and research. It has led historic missions like the Apollo moon landings and is currently involved in developing technologies for future space missions.'}"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "questions = [\n",
        "    {\"question\": \"Who founded SpaceX?\"},\n",
        "    {\"question\": \"Which U.S. government agency is responsible for space exploration?\"},\n",
        "    {\"question\": \"What company is focused on accelerating the transition to sustainable energy?\"},\n",
        "    {\"question\": \"Which company aims to make space travel more affordable and accessible?\"},\n",
        "    {\"question\": \"Which major American corporation is involved in both aviation and space exploration?\"},\n",
        "    {\"question\": \"What company is focused on commercial space tourism?\"}\n",
        "]\n"
      ],
      "metadata": {
        "id": "wTBdAZUO4pJ6"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Preparing the evaluation function.\n",
        "This time, we will ask the LLM to evaluate whether the context was helpful in arriving at a given answer , following the example of \" Faithfulness ,\" one of the evaluation indicators in the \" RAGAS \" framework for RAG evaluation."
      ],
      "metadata": {
        "id": "vzK5142G5AtW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "\n",
        "@weave.op()\n",
        "async def context_precision_score(question, model_output):\n",
        "    context_precision_prompt = \"\"\"Given the question, answer, and context, verify whether the context helped in reaching the provided answer.\n",
        "In the JSON output, if the context was useful, output {{verification: 1}}.\n",
        "If the context was not useful, output {{verification: 0}}.\n",
        "Output in valid JSON format only.\n",
        "\n",
        "Context:\n",
        "```\n",
        "{context}\n",
        "```\n",
        "\n",
        "Answer:\n",
        "{answer}\n",
        "\"\"\"\n",
        "\n",
        "    client = OpenAI()\n",
        "    prompt = context_precision_prompt.format(\n",
        "        question=question,\n",
        "        context=model_output[\"context\"],\n",
        "        answer=model_output[\"answer\"],\n",
        "    )\n",
        "    response = client.chat.completions.create(\n",
        "        model=\"gpt-4o\",\n",
        "        messages=[{\"role\": \"user\", \"content\": prompt}],\n",
        "        response_format={ \"type\": \"json_object\" }\n",
        "    )\n",
        "    response_message = response.choices[0].message\n",
        "    response = json.loads(response_message.content)\n",
        "    return {\n",
        "        \"verdict\": int(response[\"verification\"]) == 1,\n",
        "    }"
      ],
      "metadata": {
        "id": "yGaLODve481R"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()"
      ],
      "metadata": {
        "id": "hEolkkfz5ib3"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# weave.Evaluation\n",
        "evaluation = weave.Evaluation(\n",
        "    dataset=questions,\n",
        "    scorers=[context_precision_score]\n",
        ")"
      ],
      "metadata": {
        "id": "Ruz9jng45n3U"
      },
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "model = RAGModel(\n",
        "    model_name=\"gpt-4o\"\n",
        ")\n",
        "await evaluation.evaluate(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "xxN4Bj955rPi",
        "outputId": "9749fcde-2ce0-4ebf-dbdf-4867cd29408c"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation summary\n",
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'context_precision_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'verdict'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m6\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m2.4371865590413413\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
              "<span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'context_precision_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'verdict'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}}</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2.4371865590413413</span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üç© https://wandb.ai/aianytime07/rag-baselining/r/call/019223af-f8b0-71c0-9678-a8a1e7cd056f\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context_precision_score': {'verdict': {'true_count': 6,\n",
              "   'true_fraction': 1.0}},\n",
              " 'model_latency': {'mean': 2.4371865590413413}}"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = RAGModel(\n",
        "    model_name=\"gpt-4o-mini\"\n",
        ")\n",
        "await evaluation.evaluate(model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "NfB2tJDl5uvi",
        "outputId": "671872fa-7af5-4428-bd0a-dd33e01a24d4"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m1\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m2\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">2</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m3\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m4\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">4</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m5\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">5</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluated \u001b[1;36m6\u001b[0m of \u001b[1;36m6\u001b[0m examples\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluated <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> of <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span> examples\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "Evaluation summary\n",
              "\u001b[1m{\u001b[0m\n",
              "    \u001b[32m'context_precision_score'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'verdict'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'true_count'\u001b[0m: \u001b[1;36m6\u001b[0m, \u001b[32m'true_fraction'\u001b[0m: \u001b[1;36m1.0\u001b[0m\u001b[1m}\u001b[0m\u001b[1m}\u001b[0m,\n",
              "    \u001b[32m'model_latency'\u001b[0m: \u001b[1m{\u001b[0m\u001b[32m'mean'\u001b[0m: \u001b[1;36m3.0771077076594033\u001b[0m\u001b[1m}\u001b[0m\n",
              "\u001b[1m}\u001b[0m\n"
            ],
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Evaluation summary\n",
              "<span style=\"font-weight: bold\">{</span>\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'context_precision_score'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'verdict'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'true_count'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">6</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'true_fraction'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1.0</span><span style=\"font-weight: bold\">}}</span>,\n",
              "    <span style=\"color: #008000; text-decoration-color: #008000\">'model_latency'</span>: <span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'mean'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">3.0771077076594033</span><span style=\"font-weight: bold\">}</span>\n",
              "<span style=\"font-weight: bold\">}</span>\n",
              "</pre>\n"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üç© https://wandb.ai/aianytime07/rag-baselining/r/call/019223af-078b-7b02-92aa-4c3a9b885d3b\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'context_precision_score': {'verdict': {'true_count': 6,\n",
              "   'true_fraction': 1.0}},\n",
              " 'model_latency': {'mean': 3.0771077076594033}}"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZmHa-UqO53yW"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}